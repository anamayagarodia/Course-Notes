<!DOCTYPE html>
<html>
  <head>
    <title>MATH 146 Final Review by Raphael Koh</title>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
      });
    </script>
    <link rel="stylesheet" href="./styles.css" />
  </head>
  <body>
    <h1><a name="1"></a><b>1 </b>Vector Spaces & Dimensions</h1>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        A <b>field</b> is an algebraic system $\mathbb{F}$ having:
        <ul>
          <li>
            elements $0$, $1$, (and possibly more)
          </li>
          <li>
            operations $+, \times, -,$ and $^{-1}$
          </li>
        </ul>
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        A <b>vector space over $\mathbb{F}$</b> is a set $V$ which is closed under addition and scalar multiplication, and satisfies VS 1-8.
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem 8 (Cancellation Law)</label>:</div>
      <div id="desc">
        Suppose $V$ is a vector space and $x,y,z\in V$.  If $x+z=y+z$ then $x=y$.
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Corollary 1</label>:</div>
      <div id="desc">
        In any vector space, there is only one zero vector, denoted $0$.
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Let $V$ be a vector space over $\mathbb{F}$.  A subset $W$ of $V$ is a <b>subspace of $V$</b> if $W$, with the operations of $V$, form a vector space.
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Let $V$ be a vector space over $\mathbb{F}$. Let $x, u_1, \ldots, u_n\in V$.  $x$ is a <b>linear combination</b> of $u_1,\ldots,u_n$ if there exists $a_1,\ldots,a_n\in\mathbb{F}$ such that $x=a_1u_1+a_2u_2+\ldots+a_nu_n$
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Suppose $V$ is a vector space over $\mathbb{F}$, $W\subseteq V$.  Then, $W$ is a subspace of $V$ if and only if:
        <ol>
          <li>
            $W$ is closed under the operations (addition + scalar multiplication) of $V$.
          </li>
          <li>
            $W$ contains the zero vector of $V$.
          </li>
        </ol>
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $V$ is a vs/$\mathbb{F}$, $x\in V$, and $\phi\neq S\subseteq V$.
        <ol>
          <li>
            $x$ is a <b>linear combination of $S$</b> if $x$ is a linear combination of some vectors $u_1,\ldots,u_n\in S$.
          </li>
          <li>
            $span (S)\overset{def}{=}\{\text{all linear combos of $S$}\}$<br />
            *$span(\phi)\overset{def}{=}\{0\}$
          </li>
        </ol>
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Let $V$ be a vector space over $\mathbb{F}$, $S\subseteq V$.
        <ol>
          <li>
            $span(S)$ is a subspace of $V$
          </li>
          <li>
            $span(S)$ is the smallest subspace of $V$ containing $S$.
          </li>
        </ol>
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Let $V$ be a vs/$\mathbb{F}$, $x\in V$, and $S\subseteq V$.  $S$ is <b>linearly dependent</b> if there exist distinct vectors $u_1,\ldots,u_n\in S$ and $a_1,\ldots,a_n\in\mathbb{F}$ not all zero such that $a_1u_1+\ldots+a_nu_n=0$.
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        A set $S$ is linearly independent if $\forall$ distinct $u_1,\ldots,u_n\in S$, $\forall a_1,\ldots,a_n\in\mathbb{F}$, if $a_1u_1+\ldots+a_nu_n=0$ then $a_1=a_2=\ldots=a_n=0$.
      </div>
    </div>
    <i>Note:</i> $S=\phi$ is linearly independent because a linearly dependent set must be non-empty.  $S=\{0\}$ is linearly dependent because $a\cdot 0=0$ for any scalar $a$.
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Suppose $S$ is a linearly independent set in a vector space $V$ and $v\in V-S$.  <br />Then $S\cup\{v\}$ is linearly independent $\leftrightarrow v\not\in span(S)$.
      </div>
    </div>
    <h2>Basis and Dimensions</h2>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        A subset of a vector space $V$ is a <b>basis</b> for $V$ if it is linearly independent and spans $V$.
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        A subset $S\subseteq V$ is a <b>minimal spanning set</b> if:
        <ol type="i">
          <li>
            $span(S)=V$ <u>and</u>
          </li>
          <li>
            no proper subset of $S$ is a spanning set of $V$.
          </li>
        </ol>
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        A subset $S\subseteq V$ is a <b>maximal linearly independent</b> if:
        <ol type="i">
          <li>
            $S$ is linearly independent <u>and</u>
          </li>
          <li>
            No set $W\subseteq V$ that has $S$ as a proper subset is linearly independent.
          </li>
        </ol>
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Basis $\longleftrightarrow$ Minimal spanning set $\longleftrightarrow$ Maximal linear independent set
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Replacement Lemma</label>:</div>
      <div id="desc">
        Suppose $V$ is a vector space and $S,T\subseteq V$, $v\in V$ and
        <ul>
          <li>
            $S$ us linearly independent.
          </li>
          <li>
            $v\not\in span(S)\rightarrow S\cup\{v\}$ is linearly independent
          </li>
          <li>
            $span(S\cup T)=V$
          </li>
        </ul>
        Then $\exists x\in T$ such that $span\bigg((S\cup\{v\})\cup(T-\{x\})\bigg)=V$
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Corollary</label>:</div>
      <div id="desc">
        If $V$ is finitely-generated, then all bases for $V$ are finite and have the same size.  This unique size of the basis of $V$ is known as the <b>dimension</b> of $V$, written as $\dim (V)$.
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        If $V$ is finitely-dimensional, then every linearly independent subset can be expanded to a basis for $V$.
      </div>
    </div>
    <h1><a name="2"></a><b>2 </b>Functions Between Vector Spaces</h1>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $V$ and $W$ are vector spaces over $\mathbb{F}$.  A function $T: V\rightarrow W$ is a <b>linear transformation</b> if $T$ satisfies:
        <ol>
          <li>
            $T(x+y)=T(x)+T(y)$
          </li>
          <li>
            $T(ax)=aT(x)$
          </li>
        </ol>
      </div>
    </div>
    Properties of all linear transformations:
    <ol>
      <li>
        $T(0)=0$
      </li>
      <li>
        $T(-x)=-T(x)$
      </li>
      <li>
        $T(x-y)=T(x)-T(y)$
      </li>
      <li>
        $T(a_1x_1+\ldots+a_nx_n)=a_1T(x_1)+\ldots+a_nT(x_n)$
      </li>
    </ol>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $T: V\rightarrow W$ is linear, then
        <ul style="list-style: none;">
          <li>
            $R(T)$ is the <b>range</b> of $T$ such that $R(T)=\{T(x):x\in V\}$ and $R(T)$ is a subspace of $W$.
          </li>
          <li>
            $N(T)$ is the <b>nullspace</b> of $T$ such that $\{x\in V:T(x)=0\}$ and $N(T)$ is a subspace of $V$.
          </li>
        </ul>
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Suppose $T: V\rightarrow W$ is linear and $V= span(v_1,\ldots, v_n)$ then $R(T)=span(T(v_1),\ldots,T(v_n))$.
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Suppose $T: V\rightarrow W$ is linear.
        <ul style="list-style:none;">
          <li>
            $T$ is <i>surjective</i> $\leftrightarrow R(T)=W$
          </li>
          <li>
            $T$ is <i>injective</i> $\leftrightarrow N(T)=\{0\}$
          </li>
        </ul>
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $T: V\rightarrow W$ is linear and $\dim (V)<\infty$.
        <ul style="list-style:none;">
          <li>
            $rank(T)=\dim(R(T))$
          </li>
          <li>
            $nullity(T)=\dim(N(T))$
          </li>
        </ul>
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Rank-Nullity Theorem</label>:</div>
      <div id="desc">
        Suppose $T: V\rightarrow W$ is linear, then $rank(T)+nullity(T)=\dim(V)$.
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Corollary</label>:</div>
      <div id="desc">
        Suppose $T: V\rightarrow V$ and $\dim V<\infty$.  Then $T$ is injective $\leftrightarrow T$ is surjective.  In other words, $T$ is <i>bijective</i>.
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $V$ is a finite-dimensional vector space over $\mathbb{F}$ and $\beta=(v_1,\ldots, v_n)$ is an ordered basis for $V$, and $x\in V$.  The <b>coordinate vector of $x$ relative to $\beta$</b> is the $n$-tuple $(a_1,\ldots, a_n)\in\mathbb{F}^n$ unqiuely satisfying $x=a_1v_1+\ldots+a_nv_n$, and is denoted by
        $$[x]_\beta=\left(\begin{smallmatrix}a_1\\\vdots\\a_n\end{smallmatrix}\right)$$
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Suppose $V$ is a finite-dimensional vector space over $\mathbb{F}$ where $\dim(V)=n$ and $\beta=(v_1,\ldots,v_n)$ is an ordered basis. Then $[]_\beta:V\rightarrow\mathbb{F}^n$ is a <u>bijective linear transformation</u> or an <u>isomorphism</u>.
      </div>
    </div>
    Facts:
    <ol>
      <li>
        If $T:V\rightarrow W$ is an isomorphism, then $T^{-1}:W\rightarrow V$ is an isomorphism.
      </li>
      <li>
        If $T:V\rightarrow W$ and $U:W\rightarrow X$ are isomorphisms, then $U\circ T: V\rightarrow X$ is an isomorphism.
      </li>
    </ol>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $V,W$ are vs$/\mathbb{F}$.  $V$ is <u>isomorphic</u> to $W$ if $\exists$ isomorphism $T:V\rightarrow W$.
      </div>
    </div>
    <h3>Coordinating Linear Transformations</h3>
    Suppose $T:V\rightarrow W$ where $V,W$ are finite-dimensional.  Let $\beta=(v_1,\ldots,v_n),\gamma=(w_1,\ldots,w_m)$.  We observe that
    <ul>
      <li>
        $T$ is completely determined by $T(v_1),T(v_2),\ldots,T(v_n)$.
      </li>
      <li>
        Each $T(v_j)$ is a vector in $W$.
      </li>
      <li>
        Each $T(v_j)$ is characterized by its coordinate vector $[T(v_j)]_\gamma\in\mathbb{F}^n$.
      </li>
    </ul>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        In the above context, the <b>matrix representation of $T$</b> for $\beta$ and $\gamma$, denoted as $[T]_\beta^\gamma$, is the $mxn$ matrix in $M_{m\times n}(\mathbb{F})$ whose $j$th column is $[T(v_j)]_\gamma$.<br />
        So, $Col_j([T]_\beta^\gamma)=[T(v_j)]_\gamma$.
      </div>
    </div>
    Steps to form the matrix representation of $T$ for $\beta$ and $\gamma$:
    <ol>
      <li>
        Apply $T$ to each vector in $\beta$.
      </li>
      <li>
        Find coordinate vector of $T(v_j)$ relative to $\gamma$.
      </li>
      <li>
        Combine the column vectors to form the $m\times n$ matrix.
      </li>
    </ol>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Suppose $T:V\rightarrow W$ is linear and $V,W$ is a finite-dimensional vector space over $\mathbb{F}$ and $\beta=(v_1,\ldots,v_n)$, $\gamma=(w_1,\ldots,w_m)$ are ordered bases for $V,W$.  Then, for any $x\in V$,
        $$[T(x)]_\gamma=[T]_\beta^\gamma\cdot[x]_\beta$$
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        $$[U]_\beta^\gamma\cdot[T]_\alpha^\beta=[U\circ T]_\alpha^\gamma$$
      </div>
    </div>
    Notation:
    <ul style="list-style:none;">
      <li>
         $\mathcal{L}(V,W)=\{$ all linear transformations $V\rightarrow W\ \}$
      </li>
      <li>
        $\mathcal{L}(V,V)=\mathcal{L}(V)$
      </li>
    </ul>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $\mathbb{F}$ is a field and $A\in M_{m\times n}(\mathbb{F})$.  We define $L_A: \mathbb{F}^n\rightarrow\mathbb{F}^m$ given by $L_A(x)=Ax$.
      </div>
    </div>
    Let $\beta_n$ be the standard ordered basis for $\mathbb{F}^n$, and let $\beta_m$ be the standard ordered basis for $\mathbb{F}^m$.  Note that $\forall x\in\mathbb{F}^m$, $[x]_{\beta_m}=x$.  To find $[L_A]_{\beta_n}^{\beta_m}$, we must find $L_A(e_1), \ldots,L_A(e_n)$.
    $$L_A(e_1)=Ae_1=\left(\begin{smallmatrix}a_{11}\\a_{21}\\\vdots\\a_{m1}\end{smallmatrix}\right)=Col_1(A)$$
    For all $j=1,\ldots, n$, $L_A(e_j)=Col_j(A)$. Since $[x]_{\beta_m}=x$, the $j$th column of $[L_A]_{\beta_n}^{\beta_m}=L_A(e_j)=Col_j(A)$.
    <div id="thm" class="nocolour">
      <div id="title"><label>Corollary</label>:</div>
      <div id="desc">
        $R(L_A)=span(Col_1(A),\ldots,Col_n(A))$ or "range of $L_A=$ column space of $A$"
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        Suppose $A\in M_{m\times n}(\mathbb{F})$. $A$ is <u>invertible</u> if $\exists B\in M_{m\times n}(\mathbb{F})$ satisfying $AB=I_n$ amd $BA=I_n$.<br />
        If $A,B$ are invertible, then $AB$ is invertible and $(AB)^{-1}=B^{-1}A^{-1}$
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        Let $Q=[I_V]_\beta^\gamma$, then
        <ol>
          <li>
            $Q$ is invertible.
          </li>
          <li>
            For any $x\in V$, $Q\cdot [x]_\beta=[I_V]_\beta^\gamma\cdot [x]_\gamma=[I_V(x)]_\gamma=[x]_\gamma$
          </li>
        </ol>
      </div>
    </div>
    <div id="def" class="nocolour">
      <div id="title"><label>Definition</label>:</div>
      <div id="desc">
        $Q=[I_V]_\beta^\gamma$ is called the <b>change of coordinate matrix from $\beta$ to $\gamma$</b>.
      </div>
    </div>
    <div id="thm" class="nocolour">
      <div id="title"><label>Theorem</label>:</div>
      <div id="desc">
        $$\begin{align*}
          [T]_\beta=Q^{-1}[T]_\gamma Q&=Q^{-1}[T]_\gamma [I_V]_\beta^\gamma\\
          &=[I_V]_\gamma^\beta[T]_\beta^\gamma\\
          &=[T]_\beta\quad\square
        \end{align*}$$
      </div>
    </div>
  </body>
</html>
